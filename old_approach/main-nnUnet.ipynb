{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install huggingface_hub - q\n",
    "#%pip install git+https://github.com/facebookresearch/segment-anything-2/ -q\n",
    "#%pip install -r https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/requirements.txt - q\n",
    "%pip install plotly -q\n",
    "%pip install pydicom scikit-image albumentations rasterio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakecordery/Desktop/dissertation-york/.venv/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# System, file and general.\n",
    "import sys\n",
    "import glob\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import joblib\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "from IPython import display as ipd\n",
    "\n",
    "# Data manipulation and analysis.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "tqdm.pandas()\n",
    "import pydicom as dicom\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Image.\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import albumentations as A\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from skimage import io \n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "from skimage.measure import regionprops\n",
    "from scipy.ndimage import label\n",
    "\n",
    "# Torch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Structure:\n",
    "### Load in data\n",
    "- Load in csv files for default and 'improved' data\n",
    "- Combine the default and additional dataframes\n",
    "- Add filenames to the dataframes\n",
    "    \n",
    "### Preprocess imgs\n",
    "- Load in dicom stacks\n",
    "- Crop nessecary imgs\n",
    "- Save all as png\n",
    "    \n",
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/2959692717.py:28: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if is_nan(row[i]):\n",
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/2959692717.py:29: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  row[i] = \"Normal/Mild\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>series_description</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>322.831858</td>\n",
       "      <td>227.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>320.571429</td>\n",
       "      <td>295.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>323.030303</td>\n",
       "      <td>371.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>335.292035</td>\n",
       "      <td>427.327434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4003253</td>\n",
       "      <td>702807833</td>\n",
       "      <td>Sagittal_T2_STIR</td>\n",
       "      <td>8</td>\n",
       "      <td>spinal_canal_stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>353.415929</td>\n",
       "      <td>483.964602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48687</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>11</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>219.465940</td>\n",
       "      <td>97.831063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48688</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>205.340599</td>\n",
       "      <td>140.207084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48689</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>202.724796</td>\n",
       "      <td>181.013624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48690</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>202.933333</td>\n",
       "      <td>219.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48691</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>4237840455</td>\n",
       "      <td>Sagittal_T1</td>\n",
       "      <td>12</td>\n",
       "      <td>left_neural_foraminal_narrowing</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>211.813953</td>\n",
       "      <td>259.534884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id series_description  instance_number  \\\n",
       "0         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "1         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "2         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "3         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "4         4003253   702807833   Sagittal_T2_STIR                8   \n",
       "...           ...         ...                ...              ...   \n",
       "48687  4290709089  4237840455        Sagittal_T1               11   \n",
       "48688  4290709089  4237840455        Sagittal_T1               12   \n",
       "48689  4290709089  4237840455        Sagittal_T1               12   \n",
       "48690  4290709089  4237840455        Sagittal_T1               12   \n",
       "48691  4290709089  4237840455        Sagittal_T1               12   \n",
       "\n",
       "                             condition  level           x           y  \n",
       "0                spinal_canal_stenosis  l1_l2  322.831858  227.964602  \n",
       "1                spinal_canal_stenosis  l2_l3  320.571429  295.714286  \n",
       "2                spinal_canal_stenosis  l3_l4  323.030303  371.818182  \n",
       "3                spinal_canal_stenosis  l4_l5  335.292035  427.327434  \n",
       "4                spinal_canal_stenosis  l5_s1  353.415929  483.964602  \n",
       "...                                ...    ...         ...         ...  \n",
       "48687  left_neural_foraminal_narrowing  l1_l2  219.465940   97.831063  \n",
       "48688  left_neural_foraminal_narrowing  l2_l3  205.340599  140.207084  \n",
       "48689  left_neural_foraminal_narrowing  l3_l4  202.724796  181.013624  \n",
       "48690  left_neural_foraminal_narrowing  l4_l5  202.933333  219.733333  \n",
       "48691  left_neural_foraminal_narrowing  l5_s1  211.813953  259.534884  \n",
       "\n",
       "[48692 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\n",
    "train_label_coordinates = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\n",
    "train_series_descriptions = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\n",
    "test_series_description  = pd.read_csv(\"rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n",
    "coords = pd.read_csv(\"coords_rsna_improved.csv\")\n",
    "\n",
    "train_labels = pd.merge(train_series_descriptions, train_label_coordinates, on = ['study_id', 'series_id'])\n",
    "\n",
    "# Align formatting with the train.csv file as well as the sample submission.\n",
    "condition = train_labels['condition'].to_numpy()\n",
    "reformatted_condition = np.array([cond.lower().replace(' ', '_') for cond in condition])\n",
    "train_labels.iloc[::, 4] = reformatted_condition\n",
    "\n",
    "level = train_labels['level'].to_numpy()\n",
    "reformatted_level = np.array([l.lower().replace('/', '_') for l in level])\n",
    "train_labels.iloc[::, 5] = reformatted_level\n",
    "\n",
    "series_description = train_labels['series_description'].to_numpy()\n",
    "reformatted_sd = np.array([d.replace(' ', '_').replace('/', '_') for d in series_description])\n",
    "train_labels.iloc[::, 2] = reformatted_sd\n",
    "\n",
    "def is_nan(value):\n",
    "    return pd.isna(value)\n",
    "\n",
    "def clean_nan_values(data):\n",
    "    for index, row in data.iterrows():\n",
    "        for i in range(len(row)):\n",
    "            if is_nan(row[i]):\n",
    "                row[i] = \"Normal/Mild\"\n",
    "    return data\n",
    "\n",
    "train = clean_nan_values(train)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spinal_canal_columns = train.filter(like='spinal_canal').columns\n",
    "train[spinal_canal_columns] = train[spinal_canal_columns].fillna('Normal/Mild')\n",
    "\n",
    "def fill_nan_left_and_right(df, column):\n",
    "    target_columns = df.filter(like=column).columns \n",
    "    null_rows = df[df[target_columns].isnull().any(axis=1)]\n",
    "    for level in ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']:\n",
    "        left_col = f\"left_{column}_{level}\"\n",
    "        right_col = f\"right_{column}_{level}\"\n",
    "        for index, row in null_rows.iterrows():\n",
    "            if pd.isna(row[left_col]) and pd.isna(row[right_col]):\n",
    "                df.at[index, left_col] = 'Normal/Mild'\n",
    "                df.at[index, right_col] = 'Normal/Mild'\n",
    "            \n",
    "            elif pd.isna(row[right_col]):\n",
    "                df.at[index, right_col] = row[left_col]\n",
    "            \n",
    "            elif pd.isna(row[left_col]):\n",
    "                df.at[index, left_col] = row[right_col]\n",
    "            else:\n",
    "                continue\n",
    "    return df\n",
    "\n",
    "train = fill_nan_left_and_right(train, 'neural_foraminal_narrowing')\n",
    "train = fill_nan_left_and_right(train, 'subarticular_stenosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>instance_number</th>\n",
       "      <th>condition</th>\n",
       "      <th>level</th>\n",
       "      <th>relative_x</th>\n",
       "      <th>relative_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>13</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.521148</td>\n",
       "      <td>0.325282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>l1_l2</td>\n",
       "      <td>0.516856</td>\n",
       "      <td>0.319701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>0.493773</td>\n",
       "      <td>0.400966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>6</td>\n",
       "      <td>Right Neural Foraminal Narrowing</td>\n",
       "      <td>l2_l3</td>\n",
       "      <td>0.504032</td>\n",
       "      <td>0.385531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3996069892</td>\n",
       "      <td>10996</td>\n",
       "      <td>12</td>\n",
       "      <td>Left Neural Foraminal Narrowing</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>0.487331</td>\n",
       "      <td>0.475040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58730</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>10</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l3_l4</td>\n",
       "      <td>0.511282</td>\n",
       "      <td>0.571751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58731</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>0.308594</td>\n",
       "      <td>0.667969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58732</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>9</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l4_l5</td>\n",
       "      <td>0.516697</td>\n",
       "      <td>0.671029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58733</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>-1</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58734</th>\n",
       "      <td>916362094</td>\n",
       "      <td>4294540297</td>\n",
       "      <td>10</td>\n",
       "      <td>Spinal Canal Stenosis</td>\n",
       "      <td>l5_s1</td>\n",
       "      <td>0.534747</td>\n",
       "      <td>0.761282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58735 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         study_id   series_id  instance_number  \\\n",
       "0      3996069892       10996               13   \n",
       "1      3996069892       10996                6   \n",
       "2      3996069892       10996               12   \n",
       "3      3996069892       10996                6   \n",
       "4      3996069892       10996               12   \n",
       "...           ...         ...              ...   \n",
       "58730   916362094  4294540297               10   \n",
       "58731   916362094  4294540297               -1   \n",
       "58732   916362094  4294540297                9   \n",
       "58733   916362094  4294540297               -1   \n",
       "58734   916362094  4294540297               10   \n",
       "\n",
       "                              condition  level  relative_x  relative_y  \n",
       "0       Left Neural Foraminal Narrowing  l1_l2    0.521148    0.325282  \n",
       "1      Right Neural Foraminal Narrowing  l1_l2    0.516856    0.319701  \n",
       "2       Left Neural Foraminal Narrowing  l2_l3    0.493773    0.400966  \n",
       "3      Right Neural Foraminal Narrowing  l2_l3    0.504032    0.385531  \n",
       "4       Left Neural Foraminal Narrowing  l3_l4    0.487331    0.475040  \n",
       "...                                 ...    ...         ...         ...  \n",
       "58730             Spinal Canal Stenosis  l3_l4    0.511282    0.571751  \n",
       "58731             Spinal Canal Stenosis  l4_l5    0.308594    0.667969  \n",
       "58732             Spinal Canal Stenosis  l4_l5    0.516697    0.671029  \n",
       "58733             Spinal Canal Stenosis  l5_s1    0.328125    0.796875  \n",
       "58734             Spinal Canal Stenosis  l5_s1    0.534747    0.761282  \n",
       "\n",
       "[58735 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = pd.read_csv('coords_rsna_improved.csv')\n",
    "\n",
    "coords = coords.drop(['side'], axis = 1)\n",
    "coords = coords.drop(coords.columns[0], axis=1)\n",
    "coords['level'] = [level.lower().replace('/', '_') for level in coords['level'].to_list()]\n",
    "\n",
    "coords = coords[['study_id', 'series_id', 'instance_number', 'condition', 'level', 'relative_x', 'relative_y']]\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess DICOM MRIs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dcm_img(dcm_path) -> np.ndarray:\n",
    "    dcm = dicom.dcmread(dcm_path)\n",
    "    img: np.ndarray = dcm.pixel_array\n",
    "    img = img.clip(np.percentile(img, 1), np.percentile(img, 99))\n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def convert_to_8bit(x):\n",
    "    lower, upper = np.percentile(x, (1, 99))\n",
    "    x = np.clip(x, lower, upper)\n",
    "    x = x - np.min(x)\n",
    "    x = x / np.max(x)\n",
    "    return (x * 255).astype(\"uint8\")\n",
    "\n",
    "def load_dicom_stack(dicom_folder, plane, reverse_sort=False):\n",
    "    dicom_files = glob(os.path.join(dicom_folder, \"*.dcm\"))\n",
    "    if not dicom_files:\n",
    "        raise ValueError(f\"No DICOM files found in {dicom_folder}\")\n",
    "        \n",
    "    dicoms = [dicom.dcmread(f) for f in dicom_files]\n",
    "    plane_index = {\"sagittal\": 0, \"coronal\": 1, \"axial\": 2}[plane.lower()]\n",
    "    positions = np.asarray([float(d.ImagePositionPatient[plane_index]) for d in dicoms])\n",
    "\n",
    "    idx = np.argsort(-positions if reverse_sort else positions)\n",
    "    dicoms = [dicoms[i] for i in idx]\n",
    "    max_shape = max([d.pixel_array.shape for d in dicoms])\n",
    "\n",
    "    # Normalize the shape by padding with zeros or resizing.\n",
    "    normalized_arrays, padding_array = [], []\n",
    "    for d in dicoms:\n",
    "        img = d.pixel_array.astype(\"float32\")\n",
    "        if img.shape != max_shape:\n",
    "            # Resize or pad the image to the max_shape.\n",
    "            padded_img = np.zeros(max_shape, dtype=\"float32\")\n",
    "            padded_img[:img.shape[0], :img.shape[1]] = img\n",
    "            normalized_arrays.append(padded_img)\n",
    "\n",
    "            x_padding = max_shape[1] - img.shape[1]\n",
    "            y_padding = max_shape[0] - img.shape[0]\n",
    "            padding_array.append((x_padding // 2, y_padding // 2))\n",
    "        else:\n",
    "            normalized_arrays.append(img)\n",
    "            padding_array.append((0, 0))\n",
    "\n",
    "    array = np.stack(normalized_arrays)\n",
    "    ipp = np.asarray([d.ImagePositionPatient for d in dicoms]).astype(\"float\")[idx]\n",
    "\n",
    "    return {\n",
    "        \"array\": convert_to_8bit(array), \n",
    "        \"positions\": ipp, \n",
    "        \"pixel_spacing\": np.asarray(dicoms[0].PixelSpacing).astype(\"float\"),\n",
    "        \"padding_array\": padding_array\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_DIR = \"rsna-2024-lumbar-spine-degenerative-classification/train_images\"\n",
    "normal_tl = \"normal_train_labels.csv\"\n",
    "\n",
    "if not os.path.exists(normal_tl):\n",
    "    for study_folder_path in tqdm(os.listdir(TRAIN_IMG_DIR)):\n",
    "        series_folders = os.listdir(os.path.join(TRAIN_IMG_DIR, study_folder_path))\n",
    "        for idx, series_folder in enumerate(series_folders):\n",
    "            dcm_folder_path = os.path.join(TRAIN_IMG_DIR, study_folder_path, series_folder)\n",
    "\n",
    "            df = train_labels[train_labels[\"series_id\"] == int(series_folder)]\n",
    "            try:\n",
    "                series_desc = df[\"series_description\"].values[0]\n",
    "            except:\n",
    "                print(f\"Series description for series_id: {series_folder} not found! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            plane = \"sagittal\" if series_desc != \"Axial T2\" else \"axial\"\n",
    "            dicom_data_3d = load_dicom_stack(dcm_folder_path, plane = plane)\n",
    "            padding_array = dicom_data_3d[\"padding_array\"]\n",
    "            \n",
    "            for i in range(len(df[\"x\"].to_list())):\n",
    "                x_pad, y_pad = padding_array[i]\n",
    "                df.iloc[i, df.columns.get_loc(\"x\")] = df.iloc[i, df.columns.get_loc(\"x\")] + x_pad\n",
    "                df.iloc[i, df.columns.get_loc(\"y\")] = df.iloc[i, df.columns.get_loc(\"y\")] + y_pad\n",
    "\n",
    "\n",
    "            pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "            img = dicom_data_3d[\"array\"][idx]\n",
    "            img_shape = img.shape\n",
    "\n",
    "            x_scale_factor = 224 / img_shape[1]\n",
    "            y_scale_factor = 224 / img_shape[0]\n",
    "\n",
    "            train_labels.loc[df.index, \"x\"] = df[\"x\"] * (x_scale_factor)\n",
    "            train_labels.loc[df.index, \"y\"] = df[\"y\"] * (y_scale_factor)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692\n",
      "18114\n"
     ]
    }
   ],
   "source": [
    "# Verify Coordinates are between 0 and 224.\n",
    "print(len(train_labels))\n",
    "tl_in_lims = train_labels[(train_labels[\"x\"] >= 0) & (train_labels[\"x\"] <= 224) & (train_labels[\"y\"] >= 0) & (train_labels[\"y\"] <= 224)]\n",
    "print(len(tl_in_lims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(normal_tl):\n",
    "    train_labels = pd.read_csv(normal_tl)\n",
    "else:\n",
    "    train_labels.to_csv(normal_tl, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_img(img, pixel_spacing, new_spacing):\n",
    "    current_spacing = np.array(pixel_spacing, dtype=np.float32)\n",
    "    resize_factor = current_spacing / new_spacing\n",
    "    new_shape = np.round(img.shape * resize_factor).astype(int)\n",
    "    resampled_image = resize(img, new_shape, preserve_range=True, anti_aliasing=True)\n",
    "    return resampled_image\n",
    "\n",
    "def resize_img(img):\n",
    "    return resize(img, (224, 224), preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "def normalize_img(img):\n",
    "    return (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "\n",
    "def preprocess_img(img, pixel_spacing):\n",
    "    resampled_img = resample_img(img, pixel_spacing, (1.0, 1.0))\n",
    "    resized_img = resize_img(resampled_img)\n",
    "    #denoised_img = reduce_noise(resized_img)\n",
    "    normalized_img = normalize_img(resized_img)\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions which get the dicom info and use it to create a preprocessed img, whilst also scaling the coords correctly\"\"\"\n",
    "def save_img(img, filename, save_folder):\n",
    "    os.makedirs(save_folder, exist_ok = True)\n",
    "    imageio.imwrite(os.path.join(save_folder, filename), (img * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"train_png\"):\n",
    "    for study_folder_path in tqdm(os.listdir(TRAIN_IMG_DIR)):\n",
    "        series_folders = os.listdir(os.path.join(TRAIN_IMG_DIR, study_folder_path))\n",
    "        for series_folder in series_folders:\n",
    "            dcm_folder_path = os.path.join(TRAIN_IMG_DIR, study_folder_path, series_folder)\n",
    "            df = train_series_descriptions[train_series_descriptions[\"series_id\"] == int(series_folder)]\n",
    "            try:\n",
    "                series_desc = df[\"series_description\"].values[0][0]\n",
    "            except:\n",
    "                print(f\"Series description for series_id: {series_folder} not found! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            plane = \"sagittal\" if series_desc != \"Axial T2\" else \"axial\"\n",
    "            dicom_data_3d = load_dicom_stack(dcm_folder_path, plane = plane)\n",
    "            \n",
    "            if dicom_data_3d[\"array\"].shape[0] == 0:\n",
    "                print(f\"Can't loop over size zero dicom data: {dicom_data_3d[\"array\"].shape}\")\n",
    "                continue\n",
    "            \n",
    "            for k in range(dicom_data_3d[\"array\"].shape[0]):\n",
    "                img = dicom_data_3d[\"array\"][k]\n",
    "                pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "                processed_img = preprocess_img(img, pixel_spacing)\n",
    "                save_folder = f\"train_png/{study_folder_path}/{series_folder}\"\n",
    "                filename = f\"{k+1}.png\"\n",
    "                save_img(processed_img, filename=filename, save_folder=save_folder)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"study_id\": \"first\", \"series_description\": \"first\", \"condition\": \"first\", \"level\": list, \"x\": list, \"y\": list}\n",
    "train_labels_grouped = train_labels.groupby([\"series_id\", \"instance_number\"], as_index=False).aggregate(d).reindex(columns=train_labels.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_file):\n",
    "    img_file = img_file.strip()\n",
    "    #Get img_file path, issue of a '/x' on the end.\n",
    "    if img_file[-1] == 'x':\n",
    "        img_file = img_file.removesuffix('/x')\n",
    "    return Image.open(img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147218/147218 [00:43<00:00, 3415.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147218 33670 33569 79979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_PATHS = glob(os.path.join(\"train_png\", \"*/*/*png\"))\n",
    "\n",
    "ST1_IMG_PATHS, ST2_IMG_PATHS, AX_IMG_PATHS = [], [], []\n",
    "st1_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Sagittal_T1\") | (train_series_descriptions[\"series_description\"] == \"Sagittal T1\")]\n",
    "st1_sids = st1_train_df[\"series_id\"].to_list()\n",
    "st2_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Sagittal_T2_STIR\") | (train_series_descriptions[\"series_description\"] == \"Sagittal T2/STIR\")]\n",
    "st2_sids = st2_train_df[\"series_id\"].to_list()\n",
    "ax_train_df = train_series_descriptions[(train_series_descriptions[\"series_description\"] == \"Axial_T2\") | (train_series_descriptions[\"series_description\"] == \"Axial T2\")]\n",
    "ax_sids = ax_train_df[\"series_id\"].to_list()\n",
    "\n",
    "for path in tqdm(IMG_PATHS, maxinterval=len(IMG_PATHS)):\n",
    "    if any(str(sid) in path for sid in st1_sids):\n",
    "        ST1_IMG_PATHS.append(path)\n",
    "    elif any(str(sid) in path for sid in st2_sids):\n",
    "        ST2_IMG_PATHS.append(path)\n",
    "    elif any(str(sid) in path for sid in ax_sids):\n",
    "        AX_IMG_PATHS.append(path)\n",
    "\n",
    "print(len(IMG_PATHS), len(ST1_IMG_PATHS), len(ST2_IMG_PATHS), len(AX_IMG_PATHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    study_id   series_id series_description  instance_number  \\\n",
      "0    4003253   702807833   Sagittal_T2_STIR                8   \n",
      "1    4003253   702807833   Sagittal_T2_STIR                8   \n",
      "2    4003253   702807833   Sagittal_T2_STIR                8   \n",
      "3    4003253   702807833   Sagittal_T2_STIR                8   \n",
      "4    4003253   702807833   Sagittal_T2_STIR                8   \n",
      "5    4003253  1054713880        Sagittal_T1                4   \n",
      "6    4003253  1054713880        Sagittal_T1                4   \n",
      "7    4003253  1054713880        Sagittal_T1                5   \n",
      "8    4003253  1054713880        Sagittal_T1                6   \n",
      "9    4003253  1054713880        Sagittal_T1                6   \n",
      "10   4003253  1054713880        Sagittal_T1               11   \n",
      "11   4003253  1054713880        Sagittal_T1               11   \n",
      "12   4003253  1054713880        Sagittal_T1               11   \n",
      "13   4003253  1054713880        Sagittal_T1               12   \n",
      "14   4003253  1054713880        Sagittal_T1               12   \n",
      "15   4003253  2448190387           Axial_T2                3   \n",
      "16   4003253  2448190387           Axial_T2                4   \n",
      "17   4003253  2448190387           Axial_T2               11   \n",
      "18   4003253  2448190387           Axial_T2               11   \n",
      "19   4003253  2448190387           Axial_T2               19   \n",
      "20   4003253  2448190387           Axial_T2               19   \n",
      "21   4003253  2448190387           Axial_T2               28   \n",
      "22   4003253  2448190387           Axial_T2               28   \n",
      "23   4003253  2448190387           Axial_T2               35   \n",
      "24   4003253  2448190387           Axial_T2               35   \n",
      "\n",
      "                           condition  level           x           y  \n",
      "0              spinal_canal_stenosis  l1_l2  112.991150   79.787611  \n",
      "1              spinal_canal_stenosis  l2_l3  112.200000  103.500000  \n",
      "2              spinal_canal_stenosis  l3_l4  113.060606  130.136364  \n",
      "3              spinal_canal_stenosis  l4_l5  117.352212  149.564602  \n",
      "4              spinal_canal_stenosis  l5_s1  123.695575  169.387611  \n",
      "5   right_neural_foraminal_narrowing  l4_l5  109.644359  146.906310  \n",
      "6   right_neural_foraminal_narrowing  l5_s1  115.640535  166.608031  \n",
      "7   right_neural_foraminal_narrowing  l3_l4  109.216061  122.921606  \n",
      "8   right_neural_foraminal_narrowing  l1_l2  113.499044   74.523901  \n",
      "9   right_neural_foraminal_narrowing  l2_l3  111.785851   96.795411  \n",
      "10   left_neural_foraminal_narrowing  l1_l2  114.374558   73.512367  \n",
      "11   left_neural_foraminal_narrowing  l4_l5  108.794275  146.762075  \n",
      "12   left_neural_foraminal_narrowing  l5_s1  114.975332  168.850095  \n",
      "13   left_neural_foraminal_narrowing  l2_l3  111.604240   99.236749  \n",
      "14   left_neural_foraminal_narrowing  l3_l4  109.595707  126.726297  \n",
      "15        left_subarticular_stenosis  l1_l2  125.388514  112.864865  \n",
      "16       right_subarticular_stenosis  l1_l2  101.702140  111.037249  \n",
      "17        left_subarticular_stenosis  l2_l3  126.685811  111.135135  \n",
      "18       right_subarticular_stenosis  l2_l3  102.130029  109.967526  \n",
      "19        left_subarticular_stenosis  l3_l4  123.226351  110.270270  \n",
      "20       right_subarticular_stenosis  l3_l4   99.990583  109.325692  \n",
      "21        left_subarticular_stenosis  l4_l5  121.064189  109.837838  \n",
      "22       right_subarticular_stenosis  l4_l5  103.199752  110.609360  \n",
      "23        left_subarticular_stenosis  l5_s1  125.820946  113.297297  \n",
      "24       right_subarticular_stenosis  l5_s1  102.130029  112.962751  \n"
     ]
    }
   ],
   "source": [
    "# Choosing patient 4003253, as they have many conditions.\n",
    "ex_df = train_labels[train_labels['study_id'] == 4003253]\n",
    "print(ex_df)\n",
    "\n",
    "def display_patient(df):\n",
    "    df = df.astype(str)\n",
    "    df[['x', 'y']] = df[['x', 'y']].astype(float)\n",
    "    for i in df['instance_number'].to_list():\n",
    "        temp_df = df[df['instance_number'] == i]\n",
    "        filepath = os.path.join('train_png', str(temp_df['study_id'].unique()[0]), str(temp_df['series_id'].unique()[0]), f'{str(i)}.png')\n",
    "        if os.path.exists(filepath):\n",
    "            img = cv2.imread(filepath)\n",
    "            plt.imshow(img)\n",
    "            plt.scatter(temp_df['x'].to_numpy(), temp_df['y'].to_numpy(), c='red')\n",
    "            #plt.title(f'Study {temp_df['study_id'].unique(), temp_df['series_id'].unique()}\\n{temp_df['condition']}')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"{filepath} is not a valid filepath!\")\n",
    "\n",
    "#display_patient(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment images from spider dataset\n",
    "### Inspired by Kaggle user Tabassum_Nova's notebook: https://www.kaggle.com/code/tabassumnova/segmentation-unet-inference-zenodo-spider?scriptVersionId=187625847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  empty\n",
       "0.0   False    341\n",
       "      True     127\n",
       "1.0   False    297\n",
       "      True     132\n",
       "Name: id, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/pretrained_unet.py:203: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=None, p=1.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpretrained_unet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Kaggle Competiton/lumbarSpineDegeneration/pretrained_unet.py:237\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m    235\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmp\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m():\n\u001b[1;32m    240\u001b[0m     model \u001b[38;5;241m=\u001b[39m smp\u001b[38;5;241m.\u001b[39mUnet(\n\u001b[1;32m    241\u001b[0m         encoder_name\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mbackbone,      \u001b[38;5;66;03m# choose encoder, e.g. mobilenet_v2 or efficientnet-b7\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         encoder_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;66;03m# use `imagenet` pre-trained weights for encoder initialization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m         activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "from pretrained_unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the now trained U-Net to segment RSNA MRIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlumbar_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_epoch-00.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m st2_predict_dataset \u001b[38;5;241m=\u001b[39m RSNATrainPredict(ST2_IMG_PATHS)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "from lumbar_dataset import *\n",
    "model_path = \"best_epoch-00.bin\"\n",
    "model = load_model(model_path).to(CFG.device)\n",
    "model.eval()\n",
    "\n",
    "st2_predict_dataset = RSNATrainPredict(ST2_IMG_PATHS)\n",
    "print(len(st2_predict_dataset))\n",
    "segmentation_dataloader = DataLoader(st2_predict_dataset, batch_size=64,\n",
    "                          num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "def save_prediction(img_path, pred):\n",
    "    filename = img_path.replace('train_png', 'nnUNet_segments').replace('png', 'npy')\n",
    "    folder_path = \"/\".join(filename.split('/')[:-1])\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    gray_mask = pred[:, :, 0]\n",
    "    np.save(filename, gray_mask)\n",
    "\n",
    "def process_and_save(data):\n",
    "    img, img_paths = data[\"img\"].to(CFG.device), data[\"img_path\"]\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = (nn.Sigmoid()(pred) > 0.5).float()\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    pred = np.transpose(pred, (0, 2, 3, 1)) \n",
    "    for k in range(pred.shape[0]): #Batch_size.\n",
    "        current_pred, current_instance = pred[k], img_paths[k].split('/')[-1].split('.')[0]\n",
    "        if int(current_instance) <= 3 and np.count_nonzero(current_pred == 1.) > 50: #Need to mess around with it to find the best miniumum number of pixels.\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "        elif int(current_instance) <= 3 and np.count_nonzero(current_pred == 1.) > 50: #Again, do testing.\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "        elif np.count_nonzero(current_pred == 1.) > 50:\n",
    "            save_prediction(img_paths[k], current_pred) \n",
    "\n",
    "if not os.path.exists(\"nnUNet_segments\"):\n",
    "    for data in tqdm(segmentation_dataloader, total=int(len(st2_predict_dataset) / 64)):\n",
    "        process_and_save(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RSNATrainPredict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m st1_predict_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mRSNATrainPredict\u001b[49m(ST1_IMG_PATHS)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(st1_predict_dataset))\n\u001b[1;32m      3\u001b[0m segmentation_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(st1_predict_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      4\u001b[0m                           num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RSNATrainPredict' is not defined"
     ]
    }
   ],
   "source": [
    "st1_predict_dataset = RSNATrainPredict(ST1_IMG_PATHS)\n",
    "print(len(st1_predict_dataset))\n",
    "segmentation_dataloader = DataLoader(st1_predict_dataset, batch_size=64,\n",
    "                          num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "if not os.path.exists(\"nnUNet_segments\"):\n",
    "    for data in tqdm(segmentation_dataloader, total=int(len(st1_predict_dataset) / 64)):\n",
    "        process_and_save(data)\n",
    "\n",
    "print(len(glob(os.path.join(\"nnUNet_segments\", \"*/*/*npy\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nnU-Net dataset setup and training\n",
    "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). \n",
    "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. \n",
    "Nature methods, 18(2), 203-211."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNET_ST1_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration\"\n",
    "UNET_ST2_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration\"\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"imagesTr\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"imagesTs\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST1_DIR, \"labelsTr\"), exist_ok = True)\n",
    "\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"imagesTr\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"imagesTs\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(UNET_ST2_DIR, \"labelsTr\"), exist_ok = True)\n",
    "\n",
    "os.makedirs(\"nnUNet_preprocessed\", exist_ok = True)\n",
    "os.makedirs(\"nnUNet_results\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create dataset.json\"\"\"\n",
    "import json\n",
    "s1,s2 = \"sagittal_t1\", \"sagittal_t2\"\n",
    "lf,rf,scs = \"left_neural_foraminal_narrowing\", \"right_neural_foraminal_narrowing\", \"spinal_canal_stenosis\"\n",
    "l1,l2,l3,l4,l5 = \"l1_l2\", \"l2_l3\", \"l3_l4\", \"l4_l5\", \"l5_s1\"\n",
    "n,m,s,i = \"normal_mild\", \"moderate\", \"severe\", \"intact\"\n",
    "\n",
    "st1_classes = {\n",
    "        \"background\": 0,\n",
    "        \"other_disc\": 1,\n",
    "\n",
    "        f\"{lf}_{l1}_{n}\": 2, #Sagittal T1: left_neural_foraminal_narrowing normal_mild/moderate/severe.\n",
    "        f\"{lf}_{l2}_{n}\": 3,\n",
    "        f\"{lf}_{l3}_{n}\": 4,\n",
    "        f\"{lf}_{l4}_{n}\": 5,\n",
    "        f\"{lf}_{l5}_{n}\": 6,\n",
    "        f\"{lf}_{l1}_{m}\": 7,\n",
    "        f\"{lf}_{l2}_{m}\": 8,\n",
    "        f\"{lf}_{l3}_{m}\": 9,\n",
    "        f\"{lf}_{l4}_{m}\": 10,\n",
    "        f\"{lf}_{l5}_{m}\": 11,\n",
    "        f\"{lf}_{l1}_{s}\": 12,\n",
    "        f\"{lf}_{l2}_{s}\": 13,\n",
    "        f\"{lf}_{l3}_{s}\": 14,\n",
    "        f\"{lf}_{l4}_{s}\": 15,\n",
    "        f\"{lf}_{l5}_{s}\": 16,\n",
    "\n",
    "        f\"{rf}_{l1}_{n}\": 17, #Sagittal T1: right_neural_foraminal_narrowing normal_mild/moderate/severe.\n",
    "        f\"{rf}_{l2}_{n}\": 18,\n",
    "        f\"{rf}_{l3}_{n}\": 19,\n",
    "        f\"{rf}_{l4}_{n}\": 20,\n",
    "        f\"{rf}_{l5}_{n}\": 21,\n",
    "        f\"{rf}_{l1}_{m}\": 22,\n",
    "        f\"{rf}_{l2}_{m}\": 23,\n",
    "        f\"{rf}_{l3}_{m}\": 24,\n",
    "        f\"{rf}_{l4}_{m}\": 25,\n",
    "        f\"{rf}_{l5}_{m}\": 26,\n",
    "        f\"{rf}_{l1}_{s}\": 27,\n",
    "        f\"{rf}_{l2}_{s}\": 28,\n",
    "        f\"{rf}_{l3}_{s}\": 29,\n",
    "        f\"{rf}_{l4}_{s}\": 30,\n",
    "        f\"{rf}_{l5}_{s}\": 31,\n",
    "\n",
    "        f\"{s1}_l1\": 32, #Sagittal T1 disc.\n",
    "        f\"{s1}_l2\": 33,\n",
    "        f\"{s1}_l3\": 34,\n",
    "        f\"{s1}_l4\": 35,\n",
    "        f\"{s1}_l5\": 36,\n",
    "        f\"{s1}_s1\": 37,\n",
    "    }\n",
    "\n",
    "st2_classes = {\n",
    "        \"background\": 0,\n",
    "        \"other_disc\": 1,\n",
    "\n",
    "        f\"{scs}_{l1}_{n}\": 2, #Sagittal T2/STIR spinal_canal_stenosis normal_mild/moderate/severe.\n",
    "        f\"{scs}_{l2}_{n}\": 3,\n",
    "        f\"{scs}_{l3}_{n}\": 4,\n",
    "        f\"{scs}_{l4}_{n}\": 5,\n",
    "        f\"{scs}_{l5}_{n}\": 6,\n",
    "        f\"{scs}_{l1}_{m}\": 7,\n",
    "        f\"{scs}_{l2}_{m}\": 8,\n",
    "        f\"{scs}_{l3}_{m}\": 9,\n",
    "        f\"{scs}_{l4}_{m}\": 10,\n",
    "        f\"{scs}_{l5}_{m}\": 11,\n",
    "        f\"{scs}_{l1}_{s}\": 12,\n",
    "        f\"{scs}_{l2}_{s}\": 13,\n",
    "        f\"{scs}_{l3}_{s}\": 14,\n",
    "        f\"{scs}_{l4}_{s}\": 15,\n",
    "        f\"{scs}_{l5}_{s}\": 16, \n",
    "\n",
    "        f\"{s2}_l1\": 17, #Sagittal T2/STIR disc.\n",
    "        f\"{s2}_l2\": 18,\n",
    "        f\"{s2}_l3\": 19,\n",
    "        f\"{s2}_l4\": 20,\n",
    "        f\"{s2}_l5\": 21,\n",
    "        f\"{s2}_s1\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/1008786243.py:21: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  erows = pd.concat([erows, irows], ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48692 61899\n",
      "110591\n",
      "61941\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Add 'inferenced' degenerative rows to the train_labels dataframe.\"\"\"\n",
    "def inference_rows(rows, instance):\n",
    "    rows = rows.drop_duplicates(subset = [\"level\"])\n",
    "    rows[\"instance_number\"] = instance\n",
    "    return rows\n",
    "\n",
    "erows = pd.DataFrame(columns = train_labels.columns)\n",
    "sagittal_idf = train_labels[(train_labels[\"condition\"] != \"left_subarticular_stenosis\") | (train_labels[\"condition\"] != \"right_subarticular_stenosis\")]\n",
    "print(len(sagittal_idf))\n",
    "\n",
    "for idx, chunk in sagittal_idf.groupby(\"series_id\"):\n",
    "    chunk = chunk.reset_index()\n",
    "    if len(chunk) < 2:\n",
    "        continue # Skip any with 1 row in as no data.\n",
    "\n",
    "    for instance in np.unique(chunk[\"instance_number\"].to_numpy()):\n",
    "        valid_ins = [instance - 1, instance, instance + 1]\n",
    "        valid_cond = chunk[chunk[\"instance_number\"] == instance][\"condition\"].values[0]\n",
    "        valid_rows = chunk[(chunk[\"instance_number\"].isin(valid_ins)) & (chunk[\"condition\"] == valid_cond)]\n",
    "        irows = inference_rows(valid_rows, instance)\n",
    "        erows = pd.concat([erows, irows], ignore_index = True)\n",
    "\n",
    "print(len(sagittal_idf), len(erows))\n",
    "itrain_labels = pd.concat([sagittal_idf, erows], ignore_index = True)\n",
    "print(len(itrain_labels))\n",
    "itrain_labels = itrain_labels.drop_duplicates(subset=['series_id', 'instance_number', 'level'])\n",
    "itrain_labels = itrain_labels[train_labels.columns]\n",
    "print(len(itrain_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      study_id   series_id series_description instance_number  \\\n",
      "15243  4003253  1054713880        Sagittal_T1              11   \n",
      "15244  4003253  1054713880        Sagittal_T1              11   \n",
      "15245  4003253  1054713880        Sagittal_T1              11   \n",
      "15246  4003253  1054713880        Sagittal_T1              11   \n",
      "15247  4003253  1054713880        Sagittal_T1              11   \n",
      "\n",
      "                             condition  level           x           y  \n",
      "15243  left_neural_foraminal_narrowing  l1_l2  114.374558   73.512367  \n",
      "15244  left_neural_foraminal_narrowing  l4_l5  108.794275  146.762075  \n",
      "15245  left_neural_foraminal_narrowing  l5_s1  114.975332  168.850095  \n",
      "15246  left_neural_foraminal_narrowing  l2_l3  111.604240   99.236749  \n",
      "15247  left_neural_foraminal_narrowing  l3_l4  109.595707  126.726297  \n"
     ]
    }
   ],
   "source": [
    "itrain_labels = itrain_labels.sort_values(['series_id', 'instance_number']).reset_index()\n",
    "itrain_labels = itrain_labels[train_labels.columns]\n",
    "print(itrain_labels[(itrain_labels[\"series_id\"] == 1054713880) & (itrain_labels[\"instance_number\"] == 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/3544515472.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n",
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/3544515472.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unqiue elements: ['Sagittal_T1' 'Sagittal_T2_STIR']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create appropriate dataframe containing the severity of the coordinate for the classification of each disc in each image\"\"\"\n",
    "class_df = pd.merge(itrain_labels, train_series_descriptions, on = [\"study_id\", \"series_id\"])\n",
    "class_df = class_df[class_df[\"series_description_x\"] != \"Axial_T2\"].drop(\"series_description_y\", axis = 1).rename(columns={\"series_description_x\": \"series_description\"})\n",
    "class_df = class_df.dropna()\n",
    "\n",
    "def rename_cell(col, val):\n",
    "    return f\"{col}_{val.lower().replace('/', '_')}\"\n",
    "\n",
    "def get_class(row):\n",
    "    col_name = f\"{row['condition']}_{row['level']}\"  \n",
    "    #print(col_name)\n",
    "    if col_name in row.index: \n",
    "        return row[col_name]\n",
    "    else:\n",
    "        print(f\"No column with name: {col_name}\\n{row}\"); return None\n",
    "\n",
    "def class_to_number(cell, classes):\n",
    "    return classes[cell] if classes[cell] is not None else np.nan\n",
    "\n",
    "def process_nnunet_df(class_df, classes, st1_st2):\n",
    "    train_copy = train[train.columns[:16]] #Drop subarticular columns. (Axial T2).\n",
    "    n = 1 if st1_st2 == \"st2\" else 6\n",
    "    m = 6 if st1_st2 == \"st2\" else 16\n",
    "    cols = [train.columns[0]] + list(train.columns[n:m])\n",
    "    train_copy = train[cols] #Drop correct condition columns, depending on sagt1 or t2. Including the study_id column.\n",
    "    for col in train_copy.columns[1:]:\n",
    "        train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n",
    "\n",
    "    class_df = pd.merge(class_df, train_copy, on = \"study_id\")\n",
    "    class_df['class_number'] = class_df.apply(get_class, axis=1)\n",
    "    class_df = class_df.drop(class_df.columns[8:-1], axis = 1)\n",
    "    class_df[\"class_number\"] = class_df[\"class_number\"].apply(lambda x: class_to_number(x, classes))\n",
    "    if len(class_df.dropna()) != len(class_df): print(\"nans in the dataframe\") \n",
    "    return class_df\n",
    "\n",
    "class_df = class_df.drop(\n",
    "    class_df[\n",
    "        (class_df[\"series_description\"] == \"Sagittal_T1\") & \n",
    "        (class_df[\"condition\"].str.contains('canal'))\n",
    "    ].index\n",
    ")\n",
    "\n",
    "class_df = class_df.drop(\n",
    "    class_df[\n",
    "        (class_df[\"series_description\"] == \"Sagittal_T2_STIR\") & \n",
    "        (class_df[\"condition\"].str.contains('narrowing'))\n",
    "    ].index\n",
    ")\n",
    "\n",
    "st1_class_df = process_nnunet_df(class_df[class_df[\"series_description\"] == \"Sagittal_T1\"], st1_classes, \"st1\")\n",
    "st1_class_df = st1_class_df.dropna()\n",
    "print(\"unqiue elements:\", np.unique(class_df[\"series_description\"].to_numpy()))\n",
    "st2_class_df = process_nnunet_df(class_df[class_df[\"series_description\"] == \"Sagittal_T2_STIR\"], st2_classes, \"st2\")\n",
    "st2_class_df = st2_class_df.dropna()\n",
    "\n",
    "if np.unique(st1_class_df[\"class_number\"].to_numpy()).shape[0] != 30:\n",
    "    print(\"Error in st1_class_df\") \n",
    "if np.unique(st2_class_df[\"class_number\"].to_numpy()).shape[0] != 15:\n",
    "    print(\"Error in st2_class_df\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Label the masks with the vertebrae class as well as the disc class. (From either st1_classes or st2_classes\n",
    "General Process: -> Take the highest disc from the dataframe (l1_l2)\n",
    "-> Find the center and sides of the vertebrae\n",
    "-> Fill a rectangle below the disc, not overlapping the vertebrae below, representing the disc between the two vertebrae\n",
    "-> Append to an array when completed\n",
    "-> Repeat until l5_s1 is reached\n",
    "-> Label s1\n",
    "-> Compare the array of completed discs/vertebrae to the list of all discs\n",
    "-> Move up to staring vertebrae, until all discs/vertebrae are completed\n",
    "-> Label the remaining vertebrae as \"other_disc\": 2 #The name for these is wrong, however is it unimportant for now.\n",
    "\"\"\"\n",
    "\n",
    "def auto_label_mask(mask):\n",
    "    labeled_mask, num_features = label(mask) \n",
    "    return labeled_mask\n",
    "    \n",
    "def correct_labels_for_overlap(mask, classes):\n",
    "    #First change the auto-assigned background color(s) to 0.\n",
    "    unique, counts = np.unique(mask, return_counts=True)\n",
    "    sorted_indices = np.argsort(counts)[::-1] #Sort in descending order\n",
    "    class_values = classes.values()\n",
    "    for u in unique:\n",
    "        if u == 0:\n",
    "            continue\n",
    "        if u in class_values:\n",
    "            mask[mask == u] = u + 70 #70 ensures the overlapping pixel value is now completely unique.\n",
    "    return mask\n",
    "\n",
    "def auto_label_and_correct_mask(mask, classes):\n",
    "    color_mask = auto_label_mask(mask)\n",
    "    corrected_color_mask = correct_labels_for_overlap(color_mask, classes)\n",
    "    return corrected_color_mask\n",
    "\n",
    "def disc_to_vert_and_class(highest_disc, condition):\n",
    "    n = 15 if condition == \"spinal_canal_stenosis\" else 0\n",
    "    if highest_disc == \"l1_l2\": return \"l1\", (32 - n)\n",
    "    elif highest_disc == \"l2_l3\": return \"l2\", (33 - n)\n",
    "    elif highest_disc == \"l3_l4\": return \"l3\", (34 - n)\n",
    "    elif highest_disc == \"l4_l5\": return \"l4\", (35 - n)\n",
    "    elif highest_disc == \"l5_s1\": return \"l5\", (36 - n)\n",
    "\n",
    "\n",
    "def align_verts_to_val(highest_vert, vert_val):\n",
    "    if highest_vert == \"l1\": \n",
    "        return {\"l1\": vert_val + 0, \"l2\": vert_val + 1, \"l3\": vert_val + 2, \"l4\": vert_val + 3, \"l5\": vert_val + 4, \"s1\": vert_val + 5}\n",
    "    elif highest_vert == \"l2\": \n",
    "        return {\"l1\": vert_val - 1, \"l2\": vert_val + 0, \"l3\": vert_val + 1, \"l4\": vert_val + 2, \"l5\": vert_val + 3, \"s1\": vert_val + 4}\n",
    "    elif highest_vert == \"l3\": \n",
    "        return {\"l1\": vert_val - 2, \"l2\": vert_val - 1, \"l3\": vert_val + 0, \"l4\": vert_val + 1, \"l5\": vert_val + 2, \"s1\": vert_val + 3}\n",
    "    elif highest_vert == \"l4\": \n",
    "        return {\"l1\": vert_val - 3, \"l2\": vert_val - 2, \"l3\": vert_val - 1, \"l4\": vert_val + 0, \"l5\": vert_val + 1, \"s1\": vert_val + 2}\n",
    "    elif highest_vert == \"l5\": \n",
    "        return {\"l1\": vert_val - 4, \"l2\": vert_val - 3, \"l3\": vert_val - 2, \"l4\": vert_val - 1, \"l5\": vert_val + 0, \"s1\": vert_val + 1} \n",
    "    else:\n",
    "        print(f\"Vertebrae {highest_vert} invalid!\")\n",
    "    #There is no \"s1\" condition.\n",
    "        \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "def find_vert_with_coords(mask, x, y):\n",
    "    central_x_est, central_y_est = int(x) - 11, int(y) - 8\n",
    "    vert_val = mask[central_y_est, central_x_est]\n",
    "    if vert_val == 0:\n",
    "        offsets = [(dx, dy) for dx in range(-3, 4) for dy in range(-3, 4)]\n",
    "        for dx, dy in offsets:\n",
    "            temp_x_est, temp_y_est = central_x_est + dx, central_y_est + dy\n",
    "            \n",
    "            if 0 <= temp_y_est < mask.shape[0] and 0 <= temp_x_est < mask.shape[1]:\n",
    "                vert_val = mask[temp_y_est, temp_x_est]\n",
    "                if vert_val != 0:\n",
    "                    return vert_val\n",
    "        return None\n",
    "    else:\n",
    "        return vert_val\n",
    "\n",
    "def locate_vertebrae(mask, highest_vert_str, highest_vert_class, x, y, all_vertebrae = [\"l1\", \"l2\", \"l3\", \"l4\", \"l5\", \"s1\"]):\n",
    "    vertebrae_val = {v: 0 for v in all_vertebrae}\n",
    "    #Find the highest vertebrae to act as a reference point within the image, as to what vertebrae are present and their class number.\n",
    "    vert_val = find_vert_with_coords(mask, x, y)\n",
    "    if vert_val == None:\n",
    "        return None\n",
    "    #Align this with order now.\n",
    "    vert_val_dict = align_verts_to_val(highest_vert_str, vert_val)\n",
    "    return vert_val_dict\n",
    "\n",
    "def calculate_disc_bboxes(regions):\n",
    "    #Unpack lx and lx+1 vert bboxes.\n",
    "    bboxes = []\n",
    "    for i in range(len(regions) - 1):\n",
    "        top_u, left_u, bottom_u, right_u = regions[i] #Box above.\n",
    "        top_l, left_l, bottom_l, right_l = regions[i + 1] #Box below.\n",
    "        #Choose largest out of the x values, so nothing is missed.\n",
    "        bbox = bottom_u - 3, min(left_u, left_l), top_l + 3, max(right_u + 5, right_l + 5) #Add some height to the bbox to fill dead space created otherwise.\n",
    "        bboxes.append(bbox)\n",
    "    return bboxes\n",
    "\n",
    "def label_sag_mask(path, mask, chunk, classes, class_numbers_verts):    \n",
    "    chunk = chunk.sort_values(\"level\").reset_index() #Sort down l1_l2 -> l5_s1.\n",
    "    x, y, level = chunk.x[0], chunk.y[0], chunk.level\n",
    "    highest_disc = level[0]\n",
    "    condition = chunk[\"condition\"].values[0]\n",
    "    highest_vert_str, highest_vert_class = disc_to_vert_and_class(highest_disc, condition)\n",
    "\n",
    "    vert_val_dict = locate_vertebrae(mask, highest_vert_str, highest_vert_class, x, y) #Use these values to switch the values on the color mask to their respective class values.\n",
    "    if vert_val_dict is None:\n",
    "        #print(\"vert_val_dict is None.\")\n",
    "        return None\n",
    "    for idx, vert_val in enumerate(vert_val_dict.values()):\n",
    "        mask[mask == vert_val] = class_numbers_verts[idx] #Won't line up due to them being about 20-30 difference.\n",
    "    #Assign all values but class_numbers and 0 to be a 1 (other_disc class).\n",
    "\n",
    "    class_mask = mask.copy().astype(int)\n",
    "    acceptable_vals = class_numbers_verts + [0]\n",
    "    filter_mask = ~np.isin(class_mask, acceptable_vals) #Makes all other detected islands of pixels as a default value.\n",
    "    class_mask[filter_mask] = 1 #~[0, 1, 32...37]\n",
    "\n",
    "    no_other_mask = class_mask.copy()\n",
    "    no_other_mask[no_other_mask == 1] = 0 #Make a copy of the classly labeled mask and remove the other_discs to simplify finding the disc regions between the vertebrae.\n",
    "    no_other_mask = no_other_mask.astype(int)\n",
    "    debug = np.unique(no_other_mask.copy())\n",
    "    no_verts = len(np.unique(no_other_mask)) - 1\n",
    "    regions = []\n",
    "    for i in np.unique(no_other_mask):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        temp_mask = np.where(no_other_mask == i, i, 0)\n",
    "        region = regionprops(temp_mask)\n",
    "        regions.append(region[0].bbox)\n",
    "    disc_bboxes = calculate_disc_bboxes(regions)\n",
    "\n",
    "    #Using the class numbers and the bounding boxes, fill the class mask.\n",
    "    class_numbers = chunk[\"class_number\"].to_list() #Will be the values to assign the discs to (top down).\n",
    "    def_discs = [2, 3, 4, 5, 6]\n",
    "    if \"right\" in condition:\n",
    "        def_discs = list(np.array(def_discs) + 15)\n",
    "\n",
    "    all_discs = {\"l1_l2\": 0, \"l2_l3\": 0, \"l3_l4\": 0, \"l4_l5\": 0, \"l5_s1\": 0}\n",
    "    for idx, disc in enumerate(all_discs.keys()):\n",
    "        disc_info = chunk[chunk[\"level\"] == disc]\n",
    "        if disc_info.empty:\n",
    "            all_discs[disc] = def_discs[idx]\n",
    "        else:\n",
    "            all_discs[disc] = class_numbers[0]\n",
    "            class_numbers.remove(class_numbers[0])\n",
    "\n",
    "    passive_mask = np.zeros_like(class_mask)\n",
    "    class_numbers_padded = list(all_discs.values())\n",
    "    for idx, bbox in enumerate(disc_bboxes):\n",
    "        bottom, left, top, right = bbox\n",
    "        passive_mask[bottom:top, left:right] = class_numbers_padded[idx]\n",
    "    merged_mask = np.where(class_mask > 0, class_mask, passive_mask)                                #no_discs = no_vertebrae - 1.\n",
    "    if 2 * no_verts - 3 != len(np.unique(merged_mask)) - 2: #Must follow the equation no_vertebrae + no_discs - classes[0, 1] == unique - classes[0, 1].\n",
    "        return merged_mask, True\n",
    "    else:\n",
    "        return merged_mask, False\n",
    "\n",
    "\n",
    "def save_mask_as_png(mask, fname, new_folder):\n",
    "    assert mask.shape == (224, 224)\n",
    "    fname = fname.replace(\"nnUNet_segments\", new_folder).replace(\"npy\", \"png\")\n",
    "    save_folder = \"/\".join(fname.split('/')[:-1])\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    mask = mask.astype(np.uint8)\n",
    "    mask_pil = Image.fromarray(mask)\n",
    "    mask_pil.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 8282 Sagittal T1 MRIs.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m color_mask \u001b[38;5;241m=\u001b[39m auto_label_and_correct_mask(gray_mask, st1_classes)\n\u001b[1;32m     14\u001b[0m png_path \u001b[38;5;241m=\u001b[39m segment_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnnUNet_segments\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m sag_t1_mask, not_failed \u001b[38;5;241m=\u001b[39m label_sag_mask(path \u001b[38;5;241m=\u001b[39m png_path, mask \u001b[38;5;241m=\u001b[39m color_mask, chunk \u001b[38;5;241m=\u001b[39m chunk, classes \u001b[38;5;241m=\u001b[39m st1_classes, \n\u001b[1;32m     16\u001b[0m                                 class_numbers_verts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m33\u001b[39m, \u001b[38;5;241m34\u001b[39m, \u001b[38;5;241m35\u001b[39m, \u001b[38;5;241m36\u001b[39m, \u001b[38;5;241m37\u001b[39m])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_failed:\n\u001b[1;32m     18\u001b[0m     fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessful\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessful\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# Segement RSNA S1 Images.\n",
    "fail_rates = {\"Successful\": 0, \"Fail to load\": 0, \"Fail within loop\": 0}\n",
    "print(f\"Labeling {len(st1_class_df.groupby([\"series_id\", \"instance_number\"]))} Sagittal T1 MRIs.\")\n",
    "\n",
    "for idx, chunk in st1_class_df.groupby([\"series_id\", \"instance_number\"]):\n",
    "    segment_path = os.path.join(\"nnUNet_segments\", str(chunk[\"study_id\"].values[0]),\n",
    "                                 str(chunk[\"series_id\"].values[0]), f\"{chunk[\"instance_number\"].values[0]}.npy\") \n",
    "    if os.path.isfile(segment_path):\n",
    "        gray_mask = np.load(segment_path) #Is grayscale img.\n",
    "    else:\n",
    "        fail_rates[\"Fail to load\"] = fail_rates[\"Fail to load\"] + 1\n",
    "        continue\n",
    "    color_mask = auto_label_and_correct_mask(gray_mask, st1_classes)\n",
    "    png_path = segment_path.replace(\"npy\", \"png\").replace(\"nnUNet_segments\", \"train_png\")\n",
    "    sag_t1_mask, not_failed = label_sag_mask(path = png_path, mask = color_mask, chunk = chunk, classes = st1_classes, \n",
    "                                    class_numbers_verts = [32, 33, 34, 35, 36, 37])\n",
    "    if not_failed:\n",
    "        fail_rates[\"Successful\"] = fail_rates[\"Successful\"] + 1\n",
    "        save_mask_as_png(sag_t1_mask, segment_path, 'nnUNet_segments_labeled')\n",
    "    elif not not_failed:\n",
    "        save_mask_as_png(sag_t1_mask, segment_path, 'nnUNet_segements_failed')\n",
    "        fail_rates[\"Fail within loop\"] = fail_rates[\"Fail within loop\"] + 1\n",
    "print(fail_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeling 2521 Sagittal T2 MRIs.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "save_mask_as_png() missing 1 required positional argument: 'new_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sag_t2_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessful\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuccessful\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 18\u001b[0m     \u001b[43msave_mask_as_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43msag_t2_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail within loop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fail_rates[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFail within loop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_mask_as_png() missing 1 required positional argument: 'new_folder'"
     ]
    }
   ],
   "source": [
    "# Segment RSNA S2 images.\n",
    "fail_rates = {\"Successful\": 0, \"Fail to load\": 0, \"Fail within loop\": 0}\n",
    "print(f\"Labeling {len(st2_class_df.groupby([\"series_id\", \"instance_number\"]))} Sagittal T2 MRIs.\")\n",
    "for idx, chunk in st2_class_df.groupby([\"series_id\", \"instance_number\"]):\n",
    "    segment_path = os.path.join(\"nnUNet_segments\", str(chunk[\"study_id\"].values[0]),\n",
    "                                str(chunk[\"series_id\"].values[0]), f\"{chunk[\"instance_number\"].values[0]}.npy\")\n",
    "    if os.path.isfile(segment_path):\n",
    "        gray_mask = np.load(segment_path)\n",
    "    else:\n",
    "        fail_rates[\"Fail to load\"] = fail_rates[\"Fail to load\"] + 1\n",
    "        continue\n",
    "    color_mask = auto_label_and_correct_mask(gray_mask, st2_classes)\n",
    "    png_path = segment_path.replace(\"npy\", \"png\").replace(\"nnUNet_segments\", \"train_png\")\n",
    "    sag_t2_mask = label_sag_mask(path = png_path, mask = color_mask, chunk = chunk, classes = st2_classes, \n",
    "                                    class_numbers_verts = [17, 18, 19, 20, 21, 22])\n",
    "    if sag_t2_mask is not None:\n",
    "        fail_rates[\"Successful\"] = fail_rates[\"Successful\"] + 1\n",
    "        save_mask_as_png(sag_t2_mask, segment_path)\n",
    "    else:\n",
    "        fail_rates[\"Fail within loop\"] = fail_rates[\"Fail within loop\"] + 1\n",
    "print(fail_rates)\n",
    "print(f\"Total number of Sagittal Samples: {len(glob(os.path.join(\"nnUNet_segments_labeled\", \"*/*/*png\")))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_info(path):\n",
    "    \"\"\"Takes a path in the style that RSNA use.\"\"\"\n",
    "    sp = path.split('/')\n",
    "    return sp[-3], sp[-2], sp[-1].split('.')[0] #Study_id, series_id, instance_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mask_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ST1_MASK_PATHS):\n\u001b[1;32m     46\u001b[0m     mask_path \u001b[38;5;241m=\u001b[39m ST1_MASK_PATHS\n\u001b[0;32m---> 47\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[43mmask_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnnUNet_segments_labeled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m     process_img(mask_path, img_path, ST1_MASKS_DIR, ST1_IMGS_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mST1\u001b[39m\u001b[38;5;124m\"\u001b[39m, idx \u001b[38;5;241m=\u001b[39m i)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mask_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ST2_MASK_PATHS)):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "# Stack masks and imgs on each other.\n",
    "ST1_MASKS_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration/labelsTr\"\n",
    "ST1_IMGS_DIR = \"nnUNet_raw/Dataset001_ST1_Degeneration/imagesTr\"\n",
    "ST2_MASKS_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration/labelsTr\"\n",
    "ST2_IMGS_DIR = \"nnUNet_raw/Dataset002_ST2_Degeneration/imagesTr\"\n",
    "os.makedirs(ST1_MASKS_DIR, exist_ok=True)\n",
    "os.makedirs(ST1_IMGS_DIR, exist_ok=True)\n",
    "os.makedirs(ST2_MASKS_DIR, exist_ok=True)\n",
    "os.makedirs(ST2_IMGS_DIR, exist_ok=True)\n",
    "\n",
    "def stack_arrays(img1, img2):\n",
    "    arr1 = np.array(img1).astype(np.uint8)\n",
    "    arr2 = np.array(img2).astype(np.uint8)\n",
    "    arrd = np.zeros_like(img1).astype(np.uint8)\n",
    "    arr_stacked = np.stack([arr1, arr2, arrd], axis = 1)\n",
    "    return arr_stacked.transpose(0, 2, 1)\n",
    "\n",
    "def save_as_png(img, filepath):\n",
    "    #img = (img - np.min(img)) / (np.max(img) - np.min(img)) * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    img = Image.fromarray(img)\n",
    "    img.save(filepath) \n",
    "\n",
    "def process_img(mask_path, img_path, masks_dir, imgs_dir, file_start, idx):\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    maskk = np.array(mask).astype(np.uint8)\n",
    "    img  = Image.open(img_path).convert('L')\n",
    "    img = np.array(img).astype(np.uint8)\n",
    "    new_mask_path = os.path.join(masks_dir, f\"{file_start}_{f'{idx:04d}'}.png\")\n",
    "    new_img_path = os.path.join(imgs_dir, f\"{file_start}_{f'{idx:04d}'}_0000.png\")\n",
    "    save_as_png(img, new_img_path)\n",
    "    save_as_png(maskk, new_mask_path)\n",
    "\n",
    "ST1_MASK_PATHS = []\n",
    "ST2_MASK_PATHS = []\n",
    "s1_sis = train_series_descriptions[train_series_descriptions[\"series_description\"] == \"Sagittal T1\"][\"series_id\"].to_list()\n",
    "s2_sis = train_series_descriptions[train_series_descriptions[\"series_description\"] == \"Sagittal T2/STIR\"][\"series_id\"].to_list()\n",
    "for path in glob(os.path.join(\"nnUNet_segments_labeled\", \"*/*/*png\")):\n",
    "    si = int(path.split('/')[-2])\n",
    "    if si in s1_sis:\n",
    "        ST1_MASK_PATHS.append(path)\n",
    "    elif si in s2_sis:\n",
    "        ST2_MASK_PATHS.append(path)\n",
    "\n",
    "for i, mask_path in enumerate(ST1_MASK_PATHS):\n",
    "    mask_path = ST1_MASK_PATHS\n",
    "    img_path = mask_path.replace('nnUNet_segments_labeled', 'train_png')\n",
    "    process_img(mask_path, img_path, ST1_MASKS_DIR, ST1_IMGS_DIR, \"ST1\", idx = i)\n",
    "\n",
    "\n",
    "for i, mask_path in enumerate(len(ST2_MASK_PATHS)):\n",
    "    mask_path = ST2_MASK_PATHS\n",
    "    img_path = mask_path.replace('nnUNet_segments_labeled', 'train_png')\n",
    "    process_img(mask_path, img_path, ST2_MASKS_DIR, ST2_IMGS_DIR, \"ST2\", idx = i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename images and labels.\n",
    "for i, path in enumerate(sorted(glob(os.path.join('nnUNet_raw/Dataset001_ST1_Degeneration/imagesTr', '*png')))):\n",
    "    rename = f'nnUNet_raw/Dataset001_ST1_Degeneration/imagesTr/ST1_{i:04d}_0000.png'\n",
    "    os.rename(path, rename)\n",
    "\n",
    "for i, path in enumerate(sorted(glob(os.path.join('nnUNet_raw/Dataset001_ST1_Degeneration/labelsTr', '*png')))):\n",
    "    rename = f'nnUNet_raw/Dataset001_ST1_Degeneration/labelsTr/ST1_{i:04d}.png'\n",
    "    os.rename(path, rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9104,\n",
       " 3: 8179,\n",
       " 4: 5583,\n",
       " 5: 3359,\n",
       " 6: 2489,\n",
       " 7: 264,\n",
       " 8: 1090,\n",
       " 9: 3076,\n",
       " 10: 4004,\n",
       " 11: 973,\n",
       " 12: 44,\n",
       " 13: 44,\n",
       " 14: 365,\n",
       " 15: 529,\n",
       " 16: 209,\n",
       " 17: 8739,\n",
       " 18: 7808,\n",
       " 19: 5444,\n",
       " 20: 3338,\n",
       " 21: 2224,\n",
       " 22: 353,\n",
       " 23: 1245,\n",
       " 24: 2894,\n",
       " 25: 3818,\n",
       " 26: 639,\n",
       " 27: 11,\n",
       " 28: 0,\n",
       " 29: 121,\n",
       " 30: 352,\n",
       " 31: 187}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Augment S1 to represent fair distribution of classes (2-31).\n",
    "\n",
    "def get_dist(folder, dist):\n",
    "    for path in glob.glob(os.path.join(folder, '*png')):\n",
    "        mask = np.array(Image.open(path))\n",
    "        unique = np.unique(mask)\n",
    "        for n in unique:\n",
    "            if n in dist.keys():\n",
    "                dist[n] += 1\n",
    "    return dist\n",
    "\n",
    "dist = get_dist(folder=ST1_MASKS_DIR, dist={n: 0 for n in range(2, 32)})\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearly, augmentation is needed on 6-16, 21-31.\n",
    "# Define the augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(limit=20, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    A.GaussianBlur(p=0.3),\n",
    "    A.RandomGamma(p=0.3),\n",
    "    A.ElasticTransform(p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=8, max_width=8, p=0.5)\n",
    "])\n",
    "\n",
    "augmented_numbers = list(range(6, 17)) + list(range(21, 32))\n",
    "max_img_num = len(glob.glob(os.path.join(ST1_MASKS_DIR, '*png')))\n",
    "for mask_path, img_path in zip(glob.glob(os.path.join(ST1_MASKS_DIR, '*png')), glob.glob(os.path.join(ST1_IMGS_DIR, '*png'))):\n",
    "    mask, img = np.array(Image.open(mask_path)), np.array(Image.open(img_path))\n",
    "    unique = np.unique(mask)\n",
    "    if not any(np.isin(unique, augmented_numbers)):\n",
    "        continue\n",
    "    for i in range(10):\n",
    "        # 10 Random albumentation which is also applied to the image.\n",
    "        augmented = augmentation_pipeline(image=img, mask=mask)\n",
    "        aug_img, aug_mask = augmented['image'], augmented['mask']\n",
    "\n",
    "        aug_img_pil = Image.fromarray(aug_img)\n",
    "        aug_mask_pil = Image.fromarray(aug_mask)\n",
    "\n",
    "        aug_img_pil.save(os.path.join(ST1_IMGS_DIR, f'ST1_{max_img_num + i:4d}_0000.png'))\n",
    "        aug_mask_pil.save(os.path.join(ST1_MASKS_DIR, f'ST1_{max_img_num + i:4d}.png'))\n",
    "\n",
    "    max_img_num += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 9104,\n",
       " 3: 8179,\n",
       " 4: 5583,\n",
       " 5: 3359,\n",
       " 6: 2489,\n",
       " 7: 264,\n",
       " 8: 1090,\n",
       " 9: 3076,\n",
       " 10: 4004,\n",
       " 11: 973,\n",
       " 12: 44,\n",
       " 13: 44,\n",
       " 14: 365,\n",
       " 15: 529,\n",
       " 16: 209,\n",
       " 17: 8739,\n",
       " 18: 7808,\n",
       " 19: 5444,\n",
       " 20: 3338,\n",
       " 21: 2224,\n",
       " 22: 353,\n",
       " 23: 1245,\n",
       " 24: 2894,\n",
       " 25: 3818,\n",
       " 26: 639,\n",
       " 27: 11,\n",
       " 28: 0,\n",
       " 29: 121,\n",
       " 30: 352,\n",
       " 31: 187}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check new dist.\n",
    "get_dist(ST1_MASKS_DIR, {n: 0 for n in range(2, 32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 3,\n",
       " 3: 3,\n",
       " 4: 3,\n",
       " 5: 2,\n",
       " 6: 1,\n",
       " 7: 0,\n",
       " 8: 0,\n",
       " 9: 0,\n",
       " 10: 1,\n",
       " 11: 1,\n",
       " 12: 0,\n",
       " 13: 0,\n",
       " 14: 0,\n",
       " 15: 0,\n",
       " 16: 0,\n",
       " 17: 44,\n",
       " 18: 45,\n",
       " 19: 40,\n",
       " 20: 37,\n",
       " 21: 0,\n",
       " 22: 1,\n",
       " 23: 0,\n",
       " 24: 5,\n",
       " 25: 7,\n",
       " 26: 1,\n",
       " 27: 0,\n",
       " 28: 0,\n",
       " 29: 0,\n",
       " 30: 1,\n",
       " 31: 0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are quite alot of images now in the train dataset. Try taking a subset of the entire dataset with high quality segmenatations.\n",
    "get_dist('nnUNet_raw/Dataset004_ST1/labelsTr', {n: 0 for n in range(2, 32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change filenames of train imgs and masks then move to the appropriate folder.\n",
    "def sd_to_bin(sd):\n",
    "    if sd == \"Sagittal T1\": return \"0000\"\n",
    "    if sd == \"Sagittal T2/STIR\": return \"0001\"\n",
    "    if sd == \"Axial T2\": return \"0002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2828203845 nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sd_to_bin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m sd \u001b[38;5;241m=\u001b[39m test_series_description[test_series_description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(dicom_folder\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])]\n\u001b[1;32m     10\u001b[0m sd \u001b[38;5;241m=\u001b[39m sd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_description\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m bin_sd \u001b[38;5;241m=\u001b[39m \u001b[43msd_to_bin\u001b[49m(sd)\n\u001b[1;32m     12\u001b[0m plane \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msagittal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sd \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxial T2\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxial\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m dicom_data_3d \u001b[38;5;241m=\u001b[39m load_dicom_stack(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_img_dir, dicom_folder), plane \u001b[38;5;241m=\u001b[39m plane)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sd_to_bin' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocess test images and rename to format. -> seriesID_instanceNumber_000(0,1,2).png \n",
    "test_img_dir = \"rsna-2024-lumbar-spine-degenerative-classification/test_images/44036939\"\n",
    "save_folders = [\"nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\", \"axial_test_png\", \"nnUNet_raw/Dataset002_ST2_Degeneration/imagesTs\"]\n",
    "for idx, dicom_folder in enumerate(os.listdir(test_img_dir)):\n",
    "        if idx == 0: \n",
    "            continue    \n",
    "        print(dicom_folder, save_folders[idx - 1])\n",
    "\n",
    "        sd = test_series_description[test_series_description[\"series_id\"] == int(dicom_folder.split('/')[-1])]\n",
    "        sd = sd[\"series_description\"].values[0]\n",
    "        bin_sd = sd_to_bin(sd)\n",
    "        plane = \"sagittal\" if sd != \"Axial T2\" else \"axial\"\n",
    "        dicom_data_3d = load_dicom_stack(os.path.join(test_img_dir, dicom_folder), plane = plane)\n",
    "                \n",
    "        if dicom_data_3d[\"array\"].shape[0] == 0:\n",
    "            print(f\"Dicom data size 0: {dicom_data_3d[\"array\"].shape}\")\n",
    "            continue\n",
    "                \n",
    "        save_folder = save_folders[idx - 1]\n",
    "        os.makedirs(save_folder, exist_ok = True)\n",
    "        for k in range(dicom_data_3d[\"array\"].shape[0] - 1): \n",
    "            img1 = dicom_data_3d[\"array\"][k]\n",
    "            #print(type(img1))\n",
    "            pixel_spacing = dicom_data_3d[\"pixel_spacing\"]\n",
    "            processed_img1 = preprocess_img(img1, pixel_spacing)\n",
    "            #print(type(processed_img1))\n",
    "            nn_img_path = os.path.join(save_folder, f\"ST1_{k:04d}_0000.png\") #{bin_to_sd}\n",
    "            save_as_png(processed_img1, nn_img_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1_dataset = {\n",
    "    \"name\": \"Sagittal T1 Degeneration\",\n",
    "    \"description\": \"Using Sagittal T1 images, identify areas of right/left neural foraminal narrowing\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { \n",
    "        \"0\": \"mri\", \n",
    "    }, \n",
    "    \"labels\": st1_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob(os.path.join(UNET_ST1_DIR, \"imagesTr\", \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join(UNET_ST1_DIR, 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(st1_dataset, json_file, indent=4)\n",
    "\n",
    "st2_dataset = {\n",
    "    \"name\": \"Sagittal T2/STIR Degeneration\",\n",
    "    \"description\": \"Using Sagittal T2/STIR images, identify areas of spinal canal stenosis\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { \n",
    "        \"0\": \"mri\", \n",
    "\n",
    "    }, \n",
    "    \"labels\": st2_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob(os.path.join(UNET_ST2_DIR, \"imagesTr\", \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join(UNET_ST2_DIR, 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(st2_dataset, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install nnUNet libraries.\n",
    "%pip install nnunetv2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "# Dataset002 trimmed is Dataset005_ST2\n",
    "DS5_PATH = 'nnUNet_raw/Dataset005_ST2_Trimmed'\n",
    "# Loop through DS5_PATH, deleting images not in the label folder\n",
    "MASKS = glob.glob(os.path.join(DS5_PATH, 'labelsTr', '*png'))\n",
    "IMAGES = [path.replace('labelsTr', 'imagesTr').replace('.png', '_0000.png') for path in MASKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy images from Dataset002 to DS005.\n",
    "import shutil\n",
    "IMAGES_SRC = [path.replace('Dataset005_ST2_Trimmed', 'Dataset002_ST2_Degeneration') for path in IMAGES]\n",
    "for path in IMAGES_SRC:\n",
    "    path005 = path.replace('Dataset002_ST2_Degeneration', 'Dataset005_ST2_Trimmed')\n",
    "    shutil.copy(path, path005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the images and labels into 0001 - 00NM.\n",
    "for i, (impath, labpath) in enumerate(zip(sorted(glob.glob(os.path.join(DS5_PATH, 'imagesTr', '*png'))), sorted(glob.glob(os.path.join(DS5_PATH, 'labelsTr', '*png')))), start=1):\n",
    "    new_impath = impath.replace(impath[-13:], f'{i:04d}_0000.png')\n",
    "    new_labpath = labpath.replace(labpath[-8:], f'{i:04d}.png')\n",
    "    os.rename(impath, new_impath)\n",
    "    os.rename(labpath, new_labpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jakecordery/Desktop/dissertation-york/.venv/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "# Then augment if contains numbers \n",
    "augment = list(range(7, 17))\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "augmentations = A.Compose([\n",
    "    A.HorizontalFlip(p=1.0),\n",
    "    A.Rotate(limit=45, p=1.0),                    # Rotate between -45 and 45 degrees\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=0, p=1.0),  # Shift and scale\n",
    "    A.CropAndPad(percent=(-0.2, 0.2), p=1.0),     # Random crop or padding\n",
    "    A.RandomScale(scale_limit=0.2, p=1.0)         # Scale (stretch/shrink)\n",
    "])\n",
    "\n",
    "augment = list(range(7, 17))  # Specify values to look for in the mask\n",
    "\n",
    "def augment_images(mask_path, img_path, current_index):\n",
    "    # Load mask and image\n",
    "    mask = cv2.imread(mask_path)\n",
    "    image = cv2.imread(img_path)\n",
    "    \n",
    "    # Apply augmentations and save results\n",
    "    for i in range(5):\n",
    "        # Apply augmentation\n",
    "        augmented = augmentations(image=image, mask=mask)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_mask = augmented['mask']\n",
    "\n",
    "        new_impath = img_path.replace(img_path[-13:], f'{current_index:04d}_0000.png')\n",
    "        new_labpath = mask_path.replace(mask_path[-8:], f'{current_index:04d}.png')\n",
    "   \n",
    "        cv2.imwrite(new_impath, augmented_image)\n",
    "        cv2.imwrite(new_labpath, augmented_mask)\n",
    "\n",
    "        current_index += 1\n",
    "    \n",
    "\n",
    "current_index = 1389 # New image to made.\n",
    "for labpath, impath in zip(glob.glob(os.path.join(DS5_PATH, 'labelsTr', '*png')), glob.glob(os.path.join(DS5_PATH, 'imagesTr', '*png'))):\n",
    "    mask = cv2.imread(path)\n",
    "    if np.any(np.isin(mask, augment)):\n",
    "        augment_images(labpath, impath, current_index)\n",
    "        current_index += 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ds_5_json = {\n",
    "    \"name\": \"Sagittal T2/STIR Degeneration\",\n",
    "    \"description\": \"Using Sagittal T2/STIR images, identify areas of spinal canal stenosis\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { \n",
    "        \"0\": \"mri\", \n",
    "    }, \n",
    "    \"labels\": st2_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob.glob(os.path.join('nnUNet_raw', 'Dataset005_ST2_Trimmed', \"imagesTr\", \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join('nnUNet_raw/Dataset005_ST2_Trimmed', 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(ds_5_json, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Setup folder directories.\n",
    "os.environ['nnUNet_preprocessed'] = \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_preprocessed\"\n",
    "os.environ['nnUNet_results'] = \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results\"\n",
    "os.environ['nnUNet_raw'] = \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1624789386.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    export nnUNet_preprocessed=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_preprocessed\"\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export nnUNet_preprocessed=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_preprocessed\"\n",
    "export nnUNet_results=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results\"\n",
    "export nnUNet_raw=\"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Plan and preprocess Sagittal T1 and T2 datasets.\n",
    "!nnUNetv2_plan_and_preprocess -d 1 --verify_dataset_integrity\n",
    "!nnUNetv2_plan_and_preprocess -d 2 --verify_dataset_integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Predict Dataset 001.\n",
    "!nnUNetv2_train 1 2d 5 -device mps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!nnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset001_ST1_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 001 -c 2d -f 0 --save_probabilities -device cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and Predict Dataset 002.\n",
    "!nnUNetv2_train 2 2d 0 -device mps \n",
    "!nnUNetv2_predict -i \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_raw/Dataset002_ST2_Degeneration/imagesTs\" -o \"/Users/jakecordery/Desktop/Kaggle Competiton/lumbarSpineDegeneration/nnUNet_results/output\" -d 002 -c 2d -f 0 --save_probabilities -device mps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Sagittal T1 Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Sagittal T1 performance on a select test set of the data, covering a range of severities of conditions.\n",
    "S1_PREDS_PATHS = glob(os.path.join('preds_16_11', '*png'))\n",
    "S1_LABELS_PATH = glob(os.path.join('nnUNet_raw/Dataset004_ST1/labelsTs', '*png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for each class\n",
    "st1_colors = {\n",
    "    0: (0, 0, 0),       # background (black)\n",
    "    1: (0, 0, 0), # other_disc (gray)\n",
    "    # Left Neural Foraminal Narrowing - Normal (Aesthetic Green)\n",
    "    2: (76, 175, 80),  # Light Green\n",
    "    3: (76, 175, 80),  # Light Green\n",
    "    4: (76, 175, 80),  # Light Green\n",
    "    5: (76, 175, 80),  # Light Green\n",
    "    6: (76, 175, 80),  # Light Green\n",
    "    # Left Neural Foraminal Narrowing - Moderate (Aesthetic Yellow)\n",
    "    7: (255, 235, 59), # Light Yellow\n",
    "    8: (255, 235, 59), # Light Yellow\n",
    "    9: (255, 235, 59), # Light Yellow\n",
    "    10: (255, 235, 59),# Light Yellow\n",
    "    11: (255, 235, 59),# Light Yellow\n",
    "    # Left Neural Foraminal Narrowing - Severe (Aesthetic Red)\n",
    "    12: (244, 67, 54), # Light Red\n",
    "    13: (244, 67, 54), # Light Red\n",
    "    14: (244, 67, 54), # Light Red\n",
    "    15: (244, 67, 54), # Light Red\n",
    "    16: (244, 67, 54), # Light Red\n",
    "    # Right Neural Foraminal Narrowing - Normal (Aesthetic Green)\n",
    "    17: (76, 175, 80), # Light Green\n",
    "    18: (76, 175, 80), # Light Green\n",
    "    19: (76, 175, 80), # Light Green\n",
    "    20: (76, 175, 80), # Light Green\n",
    "    21: (76, 175, 80), # Light Green\n",
    "    # Right Neural Foraminal Narrowing - Moderate (Aesthetic Yellow)\n",
    "    22: (255, 235, 59),# Light Yellow\n",
    "    23: (255, 235, 59),# Light Yellow\n",
    "    24: (255, 235, 59),# Light Yellow\n",
    "    25: (255, 235, 59),# Light Yellow\n",
    "    26: (255, 235, 59),# Light Yellow\n",
    "    # Right Neural Foraminal Narrowing - Severe (Aesthetic Red)\n",
    "    27: (244, 67, 54), # Light Red\n",
    "    28: (244, 67, 54), # Light Red\n",
    "    29: (244, 67, 54), # Light Red\n",
    "    30: (244, 67, 54), # Light Red\n",
    "    31: (244, 67, 54), # Light Red\n",
    "    \n",
    "    # Sagittal T1 Disc - Assigned a unique color range for each\n",
    "    32: (128, 128, 128),  #\n",
    "    33: (128, 128, 128),  # \n",
    "    34: (128, 128, 128),   # L3 - Darker Blue\n",
    "    35: (128, 128, 128),   # L4 - Even Darker Blue\n",
    "    36: (128, 128, 128),    # L5 - Very Dark Blue\n",
    "    37: (128, 128, 128)    # S1 - Grayish-Black\n",
    "}\n",
    "\n",
    "def apply_color_mapping(array):\n",
    "    # Create an empty color image array (224, 224, 3) for RGB channels\n",
    "    color_image = np.zeros((array.shape[0], array.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    # Apply colors to each class ID in the array\n",
    "    for class_id, color in st1_colors.items():\n",
    "        mask = (array == class_id)\n",
    "        color_image[mask] = color  # Assign the RGB color to the masked region\n",
    "    return color_image\n",
    "\n",
    "os.makedirs('colored_output', exist_ok=True)\n",
    "for i, (pred, label) in enumerate(zip(S1_PREDS_PATHS, S1_LABELS_PATH), start=1):\n",
    "    pred = cv2.imread(pred, cv2.IMREAD_GRAYSCALE)\n",
    "    label = cv2.imread(label, cv2.IMREAD_GRAYSCALE)\n",
    "    pretty_pred = apply_color_mapping(pred)\n",
    "    pretty_label = apply_color_mapping(label)\n",
    "\n",
    "    pred_path = os.path.join('colored_output', f'pred_{i}.png')\n",
    "    label_path = os.path.join('colored_output', f'label_{i}.png')\n",
    "    cv2.imwrite(pred_path, pretty_pred)\n",
    "    cv2.imwrite(label_path, pretty_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axial nnU-Net setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls, rs = \"left_subarticular_stenosis\", \"right_subarticular_stenosis\"\n",
    "ax_classes = {\n",
    "    \"background\": 0,\n",
    "\n",
    "    f\"{ls}_{l1}_{n}\": 1, #Axial: left_subarticular_stenosis n/m/s.\n",
    "    f\"{ls}_{l2}_{n}\": 2,\n",
    "    f\"{ls}_{l3}_{n}\": 3,\n",
    "    f\"{ls}_{l4}_{n}\": 4,\n",
    "    f\"{ls}_{l5}_{n}\": 5,\n",
    "    f\"{ls}_{l1}_{m}\": 6,\n",
    "    f\"{ls}_{l2}_{m}\": 7,\n",
    "    f\"{ls}_{l3}_{m}\": 8,\n",
    "    f\"{ls}_{l4}_{m}\": 9,\n",
    "    f\"{ls}_{l5}_{m}\": 10,\n",
    "    f\"{ls}_{l1}_{s}\": 11,\n",
    "    f\"{ls}_{l2}_{s}\": 12,\n",
    "    f\"{ls}_{l3}_{s}\": 13,\n",
    "    f\"{ls}_{l4}_{s}\": 14,\n",
    "    f\"{ls}_{l5}_{s}\": 15,\n",
    "\n",
    "    f\"{rs}_{l1}_{n}\": 16, #Axial: right_subarticular_stenosis n/m/s.\n",
    "    f\"{rs}_{l2}_{n}\": 17,\n",
    "    f\"{rs}_{l3}_{n}\": 18,\n",
    "    f\"{rs}_{l4}_{n}\": 19,\n",
    "    f\"{rs}_{l5}_{n}\": 20,\n",
    "    f\"{rs}_{l1}_{m}\": 21,\n",
    "    f\"{rs}_{l2}_{m}\": 22,\n",
    "    f\"{rs}_{l3}_{m}\": 23,\n",
    "    f\"{rs}_{l4}_{m}\": 24,\n",
    "    f\"{rs}_{l5}_{m}\": 25,\n",
    "    f\"{rs}_{l1}_{s}\": 26,\n",
    "    f\"{rs}_{l2}_{s}\": 27,\n",
    "    f\"{rs}_{l3}_{s}\": 28,\n",
    "    f\"{rs}_{l4}_{s}\": 29,\n",
    "    f\"{rs}_{l5}_{s}\": 30,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/bcpct8w966j66c8j5tg5wd4c0000gn/T/ipykernel_39353/3334558908.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create class_df for the axial plane\"\"\"\n",
    "def rename_cell(col, val):\n",
    "    return f\"{col}_{val.lower().replace('/', '_')}\"\n",
    "\n",
    "def get_class(row):\n",
    "    col_name = f\"{row['condition']}_{row['level']}\"  \n",
    "    if col_name in row.index: \n",
    "        return row[col_name]\n",
    "    else:\n",
    "        print(f\"No column with name: {col_name}\\n{row}\"); return None\n",
    "\n",
    "def class_to_number(cell, classes):\n",
    "    return classes[cell] if classes[cell] is not None else np.nan\n",
    "\n",
    "def aprocess_nnunet_df(class_df, classes):\n",
    "    cols = list(train.columns)\n",
    "    ax_train_cols = [cols[0]] + cols[16:]\n",
    "    train_copy = train[ax_train_cols] #Drop all but subarticular columns.\n",
    "    for col in train_copy.columns[1:]:\n",
    "        train_copy[col] = train_copy[col].apply(lambda x: rename_cell(col, x))\n",
    "\n",
    "    class_df = pd.merge(class_df, train_copy, on = \"study_id\")\n",
    "    class_df['class_number'] = class_df.apply(get_class, axis=1)\n",
    "    #class_df = class_df.drop(class_df.columns[8:-1], axis = 1)\n",
    "    class_df[\"class_number\"] = class_df[\"class_number\"].apply(lambda x: class_to_number(x, classes))\n",
    "    if len(class_df.dropna()) != len(class_df): print(\"nans in the dataframe\") \n",
    "    return class_df\n",
    "\n",
    "axtrain_labels = train_labels[(train_labels[\"series_description\"] == \"Axial T2\") | (train_labels[\"series_description\"] == \"Axial_T2\")]\n",
    "class_df = pd.merge(axtrain_labels, train_series_descriptions, on = [\"study_id\", \"series_id\"])\n",
    "class_df = class_df.dropna()\n",
    "ax_class_df = aprocess_nnunet_df(class_df, ax_classes)\n",
    "ax_class_df = ax_class_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'success': 13724, 'none': 66255}\n"
     ]
    }
   ],
   "source": [
    "# Basic axial segmentations.\n",
    "fail = {'success': 0,'none': 0}\n",
    "#Use the RSNA coordinates of the degeneration and just create a 5x5 pixel box around it and feed into nnU-Net.\n",
    "def get_coords_class_number(path):\n",
    "    sd, si, ino = path_to_info(path)\n",
    "    tdf = ax_class_df[(ax_class_df[\"series_id\"] == int(si)) & (ax_class_df[\"instance_number\"] == int(ino))]\n",
    "    if tdf.empty:\n",
    "        return None, None, None\n",
    "    else:\n",
    "        return tdf[\"x\"].values[0], tdf[\"y\"].values[0], tdf[\"class_number\"].values[0]\n",
    "    \n",
    "def create_seg_mask(x, y, class_number):\n",
    "    blank_mask = np.zeros((224, 224), dtype = np.int8)\n",
    "    #Create a 'class_number box' to do a very simple segmentation of the degenerative area.\n",
    "    blank_mask[(int(x) - 5):(int(x) + 5), (int(y) - 5):(int(y) + 5)] = class_number \n",
    "    return blank_mask.copy()\n",
    "\n",
    "def create_segments_axial(img_paths, dataset003_path=\"nnUNet_raw/Dataset003_AX2_Degeneration\", impath=\"imagesTr\", labpath=\"labelsTr\"):\n",
    "    file_idx = 0\n",
    "    os.makedirs(os.path.join(dataset003_path, impath), exist_ok = True)\n",
    "    os.makedirs(os.path.join(dataset003_path, labpath), exist_ok = True)\n",
    "    for path in img_paths:\n",
    "        x, y, class_number = get_coords_class_number(path)\n",
    "        if x is not None:\n",
    "            fail['success'] += 1\n",
    "            mask = create_seg_mask(x, y, class_number)\n",
    "            nn_img_path = os.path.join(dataset003_path, impath, f\"AX2_{f'{file_idx:04}'}_0000.png\")\n",
    "            nn_mask_path = os.path.join(dataset003_path, labpath, f\"AX2_{f'{file_idx:04d}'}.png\")\n",
    "            shutil.copy(path, nn_img_path)\n",
    "            save_as_png(mask, nn_mask_path)\n",
    "            file_idx += 1\n",
    "        else:\n",
    "            fail['none'] += 1\n",
    "\n",
    "create_segments_axial(AX_IMG_PATHS)\n",
    "print(fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2_dataset = {\n",
    "    \"name\": \"Axial T2 Degeneration\",\n",
    "    \"description\": \"\",\n",
    "    \"reference\": \"\",\n",
    "    \"licence\": \"\",\n",
    "    \"release\": \"0.0\",\n",
    "    \"tensorImageSize\": \"2D\",\n",
    "\n",
    "    \"channel_names\": { \n",
    "        \"0\": \"mri\", \n",
    "\n",
    "    }, \n",
    "    \"labels\": ax_classes,\n",
    "    \n",
    "    \"numTraining\": len(glob(os.path.join('nnUNet_raw/Dataset003_AX2_Degeneration/imagesTr', \"*png\"))), \n",
    "    \"file_ending\": \".png\"\n",
    "    }\n",
    "with open(os.path.join('nnUNet_raw/Dataset003_AX2_Degeneration', 'dataset.json'), 'w') as json_file:\n",
    "    json.dump(ax2_dataset, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13724,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(glob(os.path.join('nnUNet_raw/Dataset003_AX2_Degeneration/imagesTr', \"*png\"))), "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
